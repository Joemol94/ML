{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. IMPLEMENT SUPPORT VECTOR MACHINES MODEL FOR PERFORMING CLASSIFICATION USING WINE QUALITY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Data\n",
    "df = pd.read_csv('winequality-red.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize wine quality\n",
    "bins = (2,6,8)\n",
    "group_names = ['bad','good']\n",
    "categories = pd.cut(df['quality'], bins, labels = group_names)\n",
    "df['quality'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad     1382\n",
       "good     217\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data to X & y\n",
    "X = df.drop(['quality'], axis = 1)\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding our dependent variable:Quality column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling to X_train and X_test to classify better.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting simple linear SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier_simple = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier_simple.fit(X_train, y_train)\n",
    "#Predicting the Test Set\n",
    "y_pred_simple = classifier_simple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      "[[290   0]\n",
      " [ 30   0]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       290\n",
      "           1       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.45      0.50      0.48       320\n",
      "weighted avg       0.82      0.91      0.86       320\n",
      "\n",
      "\n",
      "AUC Score =  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model using various metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print('Confusion matrix : ')\n",
    "print(confusion_matrix(y_test, y_pred_simple))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred_simple))\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC Score = ',roc_auc_score(y_test, y_pred_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  IMPLEMENT KERNEL- BASED SUPPORT VECTOR MACHINES MODEL FOR PERFORMING CLASSIFICATION USING WINE QUALITY DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting simple polynomial kernal SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier_1 = SVC(kernel = 'poly', random_state = 0)\n",
    "classifier_1.fit(X_train, y_train)\n",
    "#Predicting the Test Set\n",
    "y_pred_1 = classifier_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      "[[280  10]\n",
      " [ 21   9]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       290\n",
      "           1       0.47      0.30      0.37        30\n",
      "\n",
      "    accuracy                           0.90       320\n",
      "   macro avg       0.70      0.63      0.66       320\n",
      "weighted avg       0.89      0.90      0.89       320\n",
      "\n",
      "\n",
      "AUC Score =  0.6327586206896552\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model using various metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print('Confusion matrix : ')\n",
    "print(confusion_matrix(y_test, y_pred_1))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred_1))\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC Score = ',roc_auc_score(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting simple polynomial kernal SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier_2 = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier_2.fit(X_train, y_train)\n",
    "#Predicting the Test Set\n",
    "y_pred_2 = classifier_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      "[[285   5]\n",
      " [ 21   9]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       290\n",
      "           1       0.64      0.30      0.41        30\n",
      "\n",
      "    accuracy                           0.92       320\n",
      "   macro avg       0.79      0.64      0.68       320\n",
      "weighted avg       0.90      0.92      0.91       320\n",
      "\n",
      "\n",
      "AUC Score =  0.6413793103448276\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model using various metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print('Confusion matrix : ')\n",
    "print(confusion_matrix(y_test, y_pred_2))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred_2))\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC Score = ',roc_auc_score(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting simple polynomial kernal SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "classifier_3 = SVC(kernel = 'sigmoid', random_state = 0)\n",
    "classifier_3.fit(X_train, y_train)\n",
    "#Predicting the Test Set\n",
    "y_pred_3 = classifier_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      "[[262  28]\n",
      " [ 14  16]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93       290\n",
      "           1       0.36      0.53      0.43        30\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.66      0.72      0.68       320\n",
      "weighted avg       0.89      0.87      0.88       320\n",
      "\n",
      "\n",
      "AUC Score =  0.7183908045977011\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model using various metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print('Confusion matrix : ')\n",
    "print(confusion_matrix(y_test, y_pred_3))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred_3))\n",
    "print()\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC Score = ',roc_auc_score(y_test, y_pred_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
